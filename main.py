import requests
import time
from datetime import datetime
import csv
import re

# Headers chung Ä‘á»ƒ gá»­i request
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
    "Accept": "application/json",
    "Referer": "https://tiki.vn/",
}

# HÃ m trÃ­ch xuáº¥t product_id vÃ  spid tá»« URL sáº£n pháº©m
def extract_tiki_ids(url):
    match = re.search(r"p(\d+)(?:.+spid=(\d+))?", url)
    product_id = match.group(1) if match else None
    spid = match.group(2) if match and match.group(2) else None
    return product_id, spid

# HÃ m láº¥y `spid` náº¿u khÃ´ng cÃ³ trong URL
def get_spid_if_missing(product_id):
    api_url = f"https://tiki.vn/api/v2/reviews?limit=1&page=1&product_id={product_id}"
    response = requests.get(api_url, headers=headers)

    if response.status_code == 200:
        data = response.json()
        first_review = data.get("data", [{}])[0]
        return first_review.get("spid")
    return None

# HÃ m láº¥y seller_id tá»« API reviews
def get_seller_id(product_id, spid):
    api_url = f"https://tiki.vn/api/v2/reviews?limit=1&page=1&spid={spid}&product_id={product_id}"
    response = requests.get(api_url, headers=headers)
    if response.status_code == 200:
        data = response.json()
        seller_id = data.get("data", [{}])[0].get("seller_id", 1)
        return seller_id
    return 1  # Máº·c Ä‘á»‹nh lÃ  1 náº¿u khÃ´ng láº¥y Ä‘Æ°á»£c

# HÃ m láº¥y tá»•ng sá»‘ trang reviews
def get_total_pages(product_id, spid, seller_id, limit=20):
    api_url = f"https://tiki.vn/api/v2/reviews?limit={limit}&page=1&spid={spid}&product_id={product_id}&seller_id={seller_id}"
    response = requests.get(api_url, headers=headers)
    if response.status_code == 200:
        data = response.json()
        total_reviews = data.get("paging", {}).get("total", 0)
        last_page = data.get("paging", {}).get("last_page", 1)
        if total_reviews == 0:
            print("âš ï¸ Sáº£n pháº©m nÃ y khÃ´ng cÃ³ Ä‘Ã¡nh giÃ¡ nÃ o!")
            return 0
        print(f"ğŸ“Œ Tá»•ng sá»‘ Ä‘Ã¡nh giÃ¡: {total_reviews}, Sá»‘ trang cáº§n láº¥y: {last_page}")
        return last_page
    else:
        print(f"âŒ Lá»—i khi láº¥y tá»•ng sá»‘ trang: {response.status_code}")
        return 0

# HÃ m crawl review tá»« trang 1 Ä‘áº¿n last_page
def crawl_reviews(product_id, spid, seller_id, output_file, limit=20):
    last_page = get_total_pages(product_id, spid, seller_id, limit)
    if last_page == 0:
        print("âŒ KhÃ´ng cÃ³ Ä‘Ã¡nh giÃ¡ Ä‘á»ƒ lÆ°u!")
        return

    all_reviews = []
    for page in range(1, last_page + 1):
        api_url = f"https://tiki.vn/api/v2/reviews?limit={limit}&page={page}&spid={spid}&product_id={product_id}&seller_id={seller_id}"
        response = requests.get(api_url, headers=headers)

        if response.status_code == 200:
            data = response.json()
            reviews = data.get("data", [])
            all_reviews.extend(reviews)
            print(f"âœ… ÄÃ£ láº¥y {len(reviews)} review tá»« trang {page}/{last_page}")
        else:
            print(f"âš ï¸ Lá»—i khi láº¥y trang {page}: {response.status_code}")

        time.sleep(1)  # TrÃ¡nh bá»‹ cháº·n

    # LÆ°u vÃ o CSV
    save_reviews_to_csv(all_reviews, output_file)
    print(f"ğŸ¯ Tá»•ng sá»‘ review Ä‘Ã£ lÆ°u: {len(all_reviews)}")

# HÃ m lÆ°u dá»¯ liá»‡u vÃ o file CSV
def save_reviews_to_csv(reviews, filename):
    with open(filename, mode="w", newline="", encoding="utf-8-sig") as file:
        writer = csv.writer(file)
        writer.writerow(["review_id", "rating", "content", "created_at"])
        for review in reviews:
            timestamp = review.get("created_at")
            formatted_date = datetime.utcfromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S") if timestamp else "N/A"
            writer.writerow([
                review.get("id"),
                review.get("rating"),
                review.get("content"),
                formatted_date,
            ])
    print(f"ğŸ“ Dá»¯ liá»‡u Ä‘Ã£ lÆ°u vÃ o {filename}")

# ğŸš€ Cháº¡y chÆ°Æ¡ng trÃ¬nh
if __name__ == "__main__":
    product_url = input("ğŸ”— Nháº­p link sáº£n pháº©m Tiki: ").strip()
    product_id, spid = extract_tiki_ids(product_url)

    if not product_id:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y product_id trong URL!")
    else:
        if not spid:
            print("ğŸ” KhÃ´ng tÃ¬m tháº¥y spid trong URL, Ä‘ang tÃ¬m kiáº¿m trÃªn API...")
            spid = get_spid_if_missing(product_id)

        if not spid:
            print("âŒ KhÃ´ng láº¥y Ä‘Æ°á»£c spid, khÃ´ng thá»ƒ tiáº¿p tá»¥c!")
        else:
            seller_id = get_seller_id(product_id, spid)
            print(f"ğŸ“Œ Tá»± Ä‘á»™ng láº¥y: product_id={product_id}, spid={spid}, seller_id={seller_id}")

            output_file = f"reviews_{product_id}.csv"
            crawl_reviews(product_id, spid, seller_id, output_file)
